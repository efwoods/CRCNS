{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "854f15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, iirnotch, periodogram\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import kurtosis\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.io import savemat\n",
    "import joblib\n",
    "from scipy.signal import hilbert\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from typing import Literal\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b74ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Filters\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = fs / 2.0\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut=1.0, highcut=200.0, fs=1000.0, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "# Apply after bandpass\n",
    "def notch_filter(data, freq=60.0, fs=1000.0, quality=30.0):\n",
    "    b, a = iirnotch(freq, quality, fs)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "# Noise Metrics for evaluation\n",
    "def compute_rmse(true, estimate):\n",
    "    return np.sqrt(np.mean((true - estimate) ** 2))\n",
    "\n",
    "# Kurtosis signal reduction > 0 shows a denoised signal\n",
    "def proportion_of_positive_kurtosis_signals(kurtosis_raw, kurtosis_denoised):\n",
    "    return (np.array([(kurtosis_raw - kurtosis_denoised) > 0]).sum() / len(kurtosis_raw)) * 100\n",
    "\n",
    "# Use a Standard scaler to reduce the mean to 0 and std to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e5a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the power envelope of each channel\n",
    "\n",
    "def band_power_envelope(ecog_signal: np.ndarray, lowcut: float, highcut: float, fs: float = 1000.0, order: int = 4) -> np.ndarray:\n",
    "    \"\"\"Computes band-limited envelope via Hilbert transform.\n",
    "    Parameters\n",
    "    ----------\n",
    "    self.ecog_signal : np.ndarray (T, channels)\n",
    "        This is the ecog signal that has been filtered.\n",
    "    lowcut : float\n",
    "        This is the lower band limit in Hz.\n",
    "    highcut : float\n",
    "        This is the upper band limit in Hz.\n",
    "    fs : float, optional\n",
    "        This is the frequency of the sample., by default 1000.0\n",
    "    order : int, optional\n",
    "        This is the Butterworth order, by default 4\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        envelope\n",
    "    \"\"\"\n",
    "    # 1. Narrowband bandpass\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    narrow = filtfilt(b, a, ecog_signal, axis=0)\n",
    "    # 2. Hilbert transform to get analytic signal\n",
    "    analytic = hilbert(narrow, axis=0)\n",
    "    # 3. Envelope = absolute value\n",
    "    envelope = np.abs(analytic)\n",
    "    return envelope\n",
    "\n",
    "def multiband_features(ecog_raw: np.ndarray, fs: float = 1000.0) -> np.ndarray:\n",
    "    \"\"\"Builds concatenated band-power features for μ, β, and high-gamma.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ecog_raw : np.ndarray\n",
    "        (T, 64)\n",
    "    fs : float, optional\n",
    "        Frequency of the sample, by default 1000.0\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        features: (T, 64, 3) (μ, β, high-gamma per electrode)\n",
    "    \"\"\"\n",
    "    mu_env = band_power_envelope(ecog_raw, lowcut=8.0, highcut=13.0, fs=fs)\n",
    "    beta_env = band_power_envelope(ecog_raw, lowcut=13.0, highcut=30.0, fs=fs)\n",
    "    hg_env = band_power_envelope(ecog_raw, lowcut=70.0, highcut=200.0, fs=fs)\n",
    "    # Concatenate along channel dimension\n",
    "    return np.concatenate([mu_env, beta_env, hg_env], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e758286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlapping_windows(ecog_values: np.ndarray, motion_values: np.ndarray, window_size: int = 20, hop_size: int = 10):\n",
    "    \"\"\"Builds overlapping windows to increase sample count and capture smoother transitions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ecog_values : np.ndarray\n",
    "        (T, features)\n",
    "    motion_values : np.ndarray\n",
    "        (T_motion, 3)_\n",
    "    window_size : int, optional\n",
    "        number of timepoints per window, by default 20\n",
    "    hop_size : int, optional\n",
    "        step bewteen windows, by default 10\n",
    "    \"\"\"\n",
    "    num_samples, num_features = ecog_values.shape\n",
    "    max_windows = (num_samples - window_size) // hop_size + 1\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for w in range(max_windows):\n",
    "        start = w * hop_size\n",
    "        end = start + window_size\n",
    "        if end > num_samples:\n",
    "            break\n",
    "        # Assign label as motion at center of window (or last timepoint)\n",
    "        X_list.append(ecog_values[start:end, :])\n",
    "        y_list.append(motion_values[min(end -1, motion_values.shape[0] -1), :])\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.stack(y_list, axis=0)\n",
    "    return X, y        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0b78df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "class EcogMotionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "# CNN/LSTM hybrid\n",
    "class EcogToMotionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN component: outputs 256 channels\n",
    "        self.convolv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),  # Fixed to 256 channels\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3)\n",
    "        )\n",
    "\n",
    "        # Bi-LSTM component (2 Layers)\n",
    "        self.lstm = nn.LSTM(input_size=256, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.attn_weight = nn.Linear(2 * 128, 1, bias=False)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(2*128, 3)  # Matches hidden_size=128\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch, 20, 64)\n",
    "        x = x.permute(0, 2, 1)  # Shape: (batch, 64, 20)\n",
    "        x = self.convolv(x)      # Shape: (batch, 256, 20)\n",
    "        x = x.permute(0, 2, 1)   # Shape: (batch, 20, 256)\n",
    "\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)  # lstm_out shape: (batch, 20, 128)\n",
    "\n",
    "        # Compute attention scores\n",
    "        # Flatten across features: attn_score[i, t] = wT * h_{i, t}\n",
    "        # Then softmax over t to get α_{i, t}\n",
    "        attn_scores = self.attn_weight(lstm_out).squeeze(-1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        # Weighted sum of LSTM outputs:\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), lstm_out).squeeze(1)\n",
    "\n",
    "        # Regression to 3D motion\n",
    "        output = self.fc(attn_applied)\n",
    "        return output\n",
    "\n",
    "# Linear Model\n",
    "class LinearEcogToMotionNet(nn.Module):\n",
    "    def __init__(self, input_channels = 64, sequence_length = 20, output_dim = 3):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_channels * sequence_length, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# LSTM\n",
    "class EcogLSTM(nn.Module):\n",
    "    def __init__(self, input_size = 64, hidden_size = 128, num_layers = 1, output_size = 3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x) # lstm_out shape: (batch_size, seq_len, hidden_size)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_output)\n",
    "        return output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72b211e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_export(model, data_loader, device, output_file_path):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "    predictions = np.concatenate(all_preds, axis=0)\n",
    "    targets = np.concatenate(all_targets, axis=0)\n",
    "    \n",
    "    # Save as .mat file for visualization\n",
    "    savemat(output_file_path, {\n",
    "        \"predictions\":predictions,\n",
    "        \"targets\": targets\n",
    "    })\n",
    "    print(\"Saved predictions to ecog_predictions.mat\")\n",
    "\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00512565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessData:\n",
    "    def __init__(self, ecog_file_path, motion_file_path):\n",
    "        self.ecog_file_path = ecog_file_path\n",
    "        self.motion_file_path = motion_file_path\n",
    "        self.ecog_data = None\n",
    "        self.motion_data = None\n",
    "        self.filtered_ecog = None\n",
    "        self.scaled_ecog = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def process(self, eval=False, window_size=20, duration_limit=900):\n",
    "        self.read_data()\n",
    "        self.common_average_reference()\n",
    "        self.filter_signal(eval=eval)\n",
    "        self.format_data(window_size=window_size, duration_limit=duration_limit)\n",
    "        return self.X, self.y\n",
    "    \n",
    "    def read_data(self):\n",
    "        self.ecog_data = pd.read_csv(self.ecog_file_path)\n",
    "        self.motion_data = pd.read_csv(self.motion_file_path)\n",
    "        return self\n",
    "\n",
    "    def common_average_reference(self):\n",
    "        # Subtract the common mean from the signals \n",
    "        self.ecog_data -= np.mean(self.ecog_data, axis=1, keepdims=True)\n",
    "        return self\n",
    "\n",
    "    def filter_signal(self, eval=False):\n",
    "        ecog_raw = self.ecog_data[self.ecog_data.columns[1:-1]].values\n",
    "\n",
    "        # Apply filters\n",
    "        filtered = bandpass_filter(ecog_raw, lowcut=1.0, highcut=200.0, fs=1000.0, order=4)\n",
    "        denoised = notch_filter(filtered, freq=60, fs=1000.0)\n",
    "\n",
    "        # Evaluate filters\n",
    "        if eval:\n",
    "            kurt_raw = kurtosis(ecog_raw, axis=0, fisher=True)\n",
    "            kurt_denoised = kurtosis(denoised, axis=0, fisher=True)\n",
    "            proportion_of_positive_kurtosis_signals(kurt_raw, kurt_denoised)\n",
    "            compute_rmse(ecog_raw, denoised)\n",
    "\n",
    "        # Compute Power Envelopes\n",
    "        features = multiband_features(denoised, fs=1000.0) # shape (T, 192)\n",
    "\n",
    "        # Identify the principal components of the network\n",
    "        pca = PCA(n_componens = 64, random_state=42)\n",
    "        reduced = pca.fit_transform(features)\n",
    "\n",
    "        # Scale\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaled_ecog = self.scaler.fit_transform(reduced)\n",
    "\n",
    "        # Replace in DataFrame\n",
    "        self.ecog_data = self.ecog_data.copy()\n",
    "        self.ecog_data[self.ecog_data.columns[1:-1]] = self.scaled_ecog\n",
    "\n",
    "        # Clean memory\n",
    "        del ecog_raw, filtered, denoised\n",
    "        gc.collect()\n",
    "        return self\n",
    "\n",
    "    def format_data(self, window_size=20, duration_limit=900):\n",
    "        ecog_df = self.ecog_data[self.ecog_data[\"Time\"] <= duration_limit]\n",
    "        motion_df = self.motion_data[self.motion_data[\"Motion_time\"] <= duration_limit]\n",
    "\n",
    "        ecog_values = ecog_df[ecog_df.columns[1:-1]].values\n",
    "        motion_values = motion_df[motion_df.columns[2:]].values\n",
    "\n",
    "        X, y = create_overlapping_windows(ecog_values, motion_values, window_size=20, hop_size=10)\n",
    "        self.X, self.y = X, y\n",
    "        \n",
    "        print(self.X.shape)\n",
    "        print(self.y.shape)    \n",
    "        \n",
    "        # Clean up\n",
    "        del ecog_values, motion_values\n",
    "        gc.collect()\n",
    "\n",
    "    def save(self):\n",
    "        output_file_path_base = self.ecog_file_path.strip(\"ecog_data.csv\")\n",
    "        joblib.dump(self.scaler, output_file_path_base + \"scaler_ecog.pkl\")\n",
    "        np.save(output_file_path_base + \"X.npy\", self.X)\n",
    "        np.save(output_file_path_base + \"y.npy\", self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a59faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=20, model_name=\"model\", example_input=torch.rand(1,20,64), checkpoint_dir=\"models/best_ecog_model.pth\"):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
    "    writer = SummaryWriter(log_dir='runs/' + model_name)\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    patience = 10 # epochs\n",
    "    \n",
    "    # Add the model graph to TensorBoard using example_input\n",
    "    if example_input is not None:\n",
    "        writer.add_graph(model, example_input.to(device))\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * X_batch.size(0)\n",
    "        avg_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                preds = model(X_batch)\n",
    "                loss = criterion(preds, y_batch)\n",
    "                running_val_loss += loss.item() * X_batch.size(0)\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_targets.append(y_batch.cpu())\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_targets = torch.cat(all_targets).numpy()\n",
    "        r2 = r2_score(all_targets, all_preds)\n",
    "        r2_scores.append(r2)\n",
    "        avg_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Train\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", avg_val_loss, epoch)\n",
    "        writer.add_scalar(\"R2/Validation\", r2, epoch)\n",
    "        writer.add_scalar(\"Learning Rate\", optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        print(f\"{model_name} Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f} | R2: {r2:.6f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Save best model checkpoint\n",
    "        if avg_val_loss < best_val_loss - 1e-5:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stop_counter = 0\n",
    "            print(f\"Model Checkpoint | epoch: {epoch} | best_val_loss: {best_val_loss}\")\n",
    "            torch.save(model.state_dict(), checkpoint_dir)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    writer.close()\n",
    "    return train_losses, val_losses, r2_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "867d2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_six_motion_outputs_for_df(df, wrist : Literal [\"LEFT\", \"RIGHT\"] = \"RIGHT\"):\n",
    "    if wrist == \"RIGHT\":\n",
    "        # Assuming your DataFrame is named df\n",
    "        # Create new zero columns\n",
    "        new_columns = ['Left_Wrist_X', 'Left_Wrist_Y', 'Left_Wrist_Z']\n",
    "        zero_data = np.zeros((df.shape[0], len(new_columns)))\n",
    "    elif wrist == \"LEFT\":\n",
    "        # Assuming your DataFrame is named df\n",
    "        # Create new zero columns\n",
    "        new_columns = ['Right_Wrist_X', 'Right_Wrist_Y', 'Right_Wrist_Z']\n",
    "        zero_data = np.zeros((df.shape[0], len(new_columns)))\n",
    "    else:\n",
    "        raise ValueError(\"wrist must be either LEFT or RIGHT\")\n",
    "    # Create a temporary DataFrame with zero columns\n",
    "    df_zeros = pd.DataFrame(zero_data, columns=new_columns)\n",
    "    # Concatenate the original DataFrame and the zero DataFrame\n",
    "    df_combined = pd.concat([df, df_zeros], axis=1)\n",
    "    # Reorder the columns to the desired order\n",
    "    desired_order = [\n",
    "        'Fsm', 'Left_Wrist_X', 'Left_Wrist_Y', 'Left_Wrist_Z',\n",
    "        'Motion_time', 'Right_Wrist_X', 'Right_Wrist_Y', 'Right_Wrist_Z'\n",
    "    ]\n",
    "    df_ordered = df_combined[desired_order]\n",
    "    del df\n",
    "    gc.collect()\n",
    "    return df_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e37a251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses_dict):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for model_name, (train_losses, val_losses) in losses_dict.items():\n",
    "        plt.plot(train_losses, label=f\"{model_name} Train\")\n",
    "        plt.plot(val_losses, label=f\"{model_name} Val\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.title(\"Training and Validation Loss Curves\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "283cc29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/linux-pc/gh/CRCNS/src/motor_cortex/data/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), \"src/\", \"motor_cortex/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6729e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_file_l = glob(os.path.join(os.getcwd(), \"src/\", \"motor_cortex/data/data/\", \"**\", \"motion*.csv\"), recursive=True)\n",
    "ecog_data_file_l = glob(os.path.join(os.getcwd(), \"src/\", \"motor_cortex/data/data/\", \"**\", \"ecog*.csv\"), recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26f274",
   "metadata": {},
   "source": [
    "# Reading only the Right Wrist data and training to detect depending on the Right Wrist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc74d3e4",
   "metadata": {},
   "source": [
    "## Bilateral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ff3bfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Bilateral/2018-07-12_(S1)/motion_data.csv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_data_file_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "907f36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_file = motion_data_file_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3a5a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_data_file = ecog_data_file_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c07bc434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Bilateral/2018-07-12_(S1)/motion_data.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cfec741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Bilateral/2018-07-12_(S1)/ecog_data.csv'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecog_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12b3a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_bilateral_2018_07_12_S1 = pd.read_csv(motion_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d41fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           0.000\n",
       "1           0.024\n",
       "2           0.044\n",
       "3           0.062\n",
       "4           0.082\n",
       "           ...   \n",
       "51288    1026.151\n",
       "51289    1026.170\n",
       "51290    1026.191\n",
       "51291    1026.211\n",
       "51292    1026.241\n",
       "Name: Motion_time, Length: 51293, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_data_bilateral_2018_07_12_S1[\"Motion_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dafb318b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 548.44,  445.42,  398.44, ...,  406.98,  382.4 ,  754.9 ],\n",
       "       [ 469.38,  417.6 ,  299.79, ...,  245.42,  405.31,  654.38],\n",
       "       [ 321.88,  202.92,  220.83, ...,   97.4 ,  346.46,  533.23],\n",
       "       ...,\n",
       "       [-298.85,  -66.67,  116.15, ..., -176.35,  -57.81,  -28.02],\n",
       "       [-389.06,  -96.04,  127.29, ..., -180.  ,  -88.54,  -81.25],\n",
       "       [-288.85,   32.4 ,  161.15, ..., -138.65, -104.17, -129.58]],\n",
       "      shape=(1024398, 64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecog_data_bilateral_2018_07_12_S1 = pd.read_csv(ecog_data_file)\n",
    "channel_data = ecog_data_bilateral_2018_07_12_S1.columns[1:-1].values\n",
    "ecog_data_bilateral_2018_07_12_S1[channel_data].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "167a762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fsm  Left_Wrist_X  Left_Wrist_Y  Left_Wrist_Z  Motion_time  \\\n",
      "0       50     -0.589976     -0.590399     -0.228992        0.000   \n",
      "1       50     -0.587234     -0.570032     -0.211194        0.024   \n",
      "2       50     -0.577829     -0.577735     -0.216256        0.044   \n",
      "3       50     -0.525398     -0.500043     -0.190533        0.062   \n",
      "4       50     -0.567822     -0.568262     -0.240272        0.082   \n",
      "...    ...           ...           ...           ...          ...   \n",
      "51288   50      0.983919      1.375122     -0.250602     1026.151   \n",
      "51289   50      0.996104      1.382786     -0.243810     1026.170   \n",
      "51290   50      0.987838      1.387219     -0.243038     1026.191   \n",
      "51291   50      0.978803      1.392886     -0.242469     1026.211   \n",
      "51292   50      1.059255      1.383485     -0.169499     1026.241   \n",
      "\n",
      "       Right_Wrist_X  Right_Wrist_Y  Right_Wrist_Z  \n",
      "0          -2.308375       0.156087       1.136016  \n",
      "1          -2.320215       0.178141       1.007657  \n",
      "2          -2.214928       0.090902       0.881989  \n",
      "3          -2.149553       0.041767       0.758740  \n",
      "4          -2.122593       0.021872       0.642614  \n",
      "...              ...            ...            ...  \n",
      "51288       1.189555       0.672937       0.693372  \n",
      "51289       1.192434       0.676611       0.612822  \n",
      "51290       1.205653       0.697864       0.532673  \n",
      "51291       1.207818       0.697904       0.456947  \n",
      "51292       1.204009       0.688064       0.389089  \n",
      "\n",
      "[51293 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(motion_data_bilateral_2018_07_12_S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80eb015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_motion_data_file = motion_data_file_l[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bb1b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_motion_data_file_df = pd.read_csv(current_motion_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5bef634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Fsm  Motion_time  Right_Wrist_X  Right_Wrist_Y  Right_Wrist_Z\n",
      "0       50        0.000      -0.400157       0.707055      -0.247075\n",
      "1       50        0.019      -0.398422       0.706933      -0.246666\n",
      "2       50        0.040      -0.393779       0.700217      -0.246530\n",
      "3       50        0.059      -0.402774       0.705328      -0.245737\n",
      "4       50        0.082      -0.394572       0.701167      -0.245586\n",
      "...    ...          ...            ...            ...            ...\n",
      "46222   50      924.813      -0.683175       0.404797      -0.382371\n",
      "46223   50      924.833      -0.679442       0.397681      -0.381935\n",
      "46224   50      924.852      -0.675566       0.394216      -0.382246\n",
      "46225   50      924.873      -0.677858       0.397714      -0.381256\n",
      "46226   50      924.892      -0.671611       0.391159      -0.381112\n",
      "\n",
      "[46227 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(current_motion_data_file_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f20d26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_motion_data_file_df_update = create_six_motion_outputs_for_df(current_motion_data_file_df, wrist=\"RIGHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c85c7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fsm</th>\n",
       "      <th>Left_Wrist_X</th>\n",
       "      <th>Left_Wrist_Y</th>\n",
       "      <th>Left_Wrist_Z</th>\n",
       "      <th>Motion_time</th>\n",
       "      <th>Right_Wrist_X</th>\n",
       "      <th>Right_Wrist_Y</th>\n",
       "      <th>Right_Wrist_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.400157</td>\n",
       "      <td>0.707055</td>\n",
       "      <td>-0.247075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.398422</td>\n",
       "      <td>0.706933</td>\n",
       "      <td>-0.246666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.393779</td>\n",
       "      <td>0.700217</td>\n",
       "      <td>-0.246530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.402774</td>\n",
       "      <td>0.705328</td>\n",
       "      <td>-0.245737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.394572</td>\n",
       "      <td>0.701167</td>\n",
       "      <td>-0.245586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46222</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.813</td>\n",
       "      <td>-0.683175</td>\n",
       "      <td>0.404797</td>\n",
       "      <td>-0.382371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46223</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.833</td>\n",
       "      <td>-0.679442</td>\n",
       "      <td>0.397681</td>\n",
       "      <td>-0.381935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46224</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.852</td>\n",
       "      <td>-0.675566</td>\n",
       "      <td>0.394216</td>\n",
       "      <td>-0.382246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46225</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.873</td>\n",
       "      <td>-0.677858</td>\n",
       "      <td>0.397714</td>\n",
       "      <td>-0.381256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46226</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.892</td>\n",
       "      <td>-0.671611</td>\n",
       "      <td>0.391159</td>\n",
       "      <td>-0.381112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46227 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fsm  Left_Wrist_X  Left_Wrist_Y  Left_Wrist_Z  Motion_time  \\\n",
       "0       50           0.0           0.0           0.0        0.000   \n",
       "1       50           0.0           0.0           0.0        0.019   \n",
       "2       50           0.0           0.0           0.0        0.040   \n",
       "3       50           0.0           0.0           0.0        0.059   \n",
       "4       50           0.0           0.0           0.0        0.082   \n",
       "...    ...           ...           ...           ...          ...   \n",
       "46222   50           0.0           0.0           0.0      924.813   \n",
       "46223   50           0.0           0.0           0.0      924.833   \n",
       "46224   50           0.0           0.0           0.0      924.852   \n",
       "46225   50           0.0           0.0           0.0      924.873   \n",
       "46226   50           0.0           0.0           0.0      924.892   \n",
       "\n",
       "       Right_Wrist_X  Right_Wrist_Y  Right_Wrist_Z  \n",
       "0          -0.400157       0.707055      -0.247075  \n",
       "1          -0.398422       0.706933      -0.246666  \n",
       "2          -0.393779       0.700217      -0.246530  \n",
       "3          -0.402774       0.705328      -0.245737  \n",
       "4          -0.394572       0.701167      -0.245586  \n",
       "...              ...            ...            ...  \n",
       "46222      -0.683175       0.404797      -0.382371  \n",
       "46223      -0.679442       0.397681      -0.381935  \n",
       "46224      -0.675566       0.394216      -0.382246  \n",
       "46225      -0.677858       0.397714      -0.381256  \n",
       "46226      -0.671611       0.391159      -0.381112  \n",
       "\n",
       "[46227 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_motion_data_file_df_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ad7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_data_bilateral_2018_07_12_S1[\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d811d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ecog_data_bilateral_2018_07_12_S1[\"Time\"], ecog_data_bilateral_2018_07_12_S1[channel_data].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_channels = ecog_data_bilateral_2018_07_12_S1.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_data_bilateral_2018_07_12_S1[ecog_channels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806049ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_bilateral_2018_07_12_S1_left_wrist = motion_data_bilateral_2018_07_12_S1[motion_data_bilateral_2018_07_12_S1.columns[1:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_bilateral_2018_07_12_S1_left_wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a05342",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_bilateral_2018_07_12_S1_left_wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_data_bilateral_2018_07_12_S1[channel_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ecog_data_bilateral_2018_07_12_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e491bb",
   "metadata": {},
   "source": [
    "## Ipsilateral Data (Right Wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd7427c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-04-29_(S1)/ecog_data.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecog_data_file_l[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d541fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-04-29_(S1)/ecog_data.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecog_data_file_l[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2de551",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ecog_data_file = ecog_data_file_l[8]\n",
    "current_motion_data_file = motion_data_file_l[8]\n",
    "preprocessor = PreprocessData(current_ecog_data_file, current_motion_data_file)\n",
    "X, y = preprocessor.process()\n",
    "preprocessor.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Ipsilateral Data\n",
    "# for index in range(6, 16):\n",
    "#     preprocessor = PreprocessData(ecog_data_file_l[index], motion_data_file_l[index])\n",
    "#     X, y = preprocessor.process()\n",
    "#     preprocessor.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_data_file_l[16:ecog_data_file_l.__len__()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae28952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess Contralateral Data\n",
    "# for index in range(16, ecog_data_file_l.__len__()):\n",
    "#     preprocessor = PreprocessData(ecog_data_file_l[index], motion_data_file_l[index])\n",
    "#     X, y = preprocessor.process()\n",
    "#     preprocessor.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "processed_data_l_X = glob(os.path.join('/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/', '**', \"**\", \"X.npy\"))\n",
    "processed_data_l_y = glob(os.path.join('/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/', '**', \"**\", \"y.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d61567",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_l_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_l_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform K-Fold Cross Validation\n",
    "# iterator = iter(processed_data_l)\n",
    "\n",
    "# for X, y in zip(iterator, iterator):\n",
    "#     print(X)\n",
    "#     print(y)\n",
    "\n",
    "# Create k-fold cross validation\n",
    "# select the best model\n",
    "# make a prediction\n",
    "# visualize the predictions in matlab\n",
    "# create a live demo\n",
    "# deploy demo onto the web\n",
    "# share results for testing with real people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f54ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-fold sets\n",
    "test_list_X = []\n",
    "train_list_X = []\n",
    "test_list_y = []\n",
    "train_list_y = []\n",
    "\n",
    "for i in range(len(processed_data_l_X)):\n",
    "    test_list_X.append(processed_data_l_X[i])\n",
    "    test_list_y.append(processed_data_l_y[i])\n",
    "    train_X = [x for idx, x in enumerate(processed_data_l_X) if idx != i]\n",
    "    train_y = [y for idx, y in enumerate(processed_data_l_y) if idx != i]\n",
    "    train_list_X.append(train_X)\n",
    "    train_list_y.append(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45412d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc06c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(train_list_X[INDEX][0])\n",
    "y = np.load(train_list_y[INDEX][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa744ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480cc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and Validation Sets\n",
    "dataset = EcogMotionDataset(X, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "# Train Linear Model\n",
    "input_channels = X.shape[2]\n",
    "sequence_length = X.shape[1]\n",
    "model = LinearEcogToMotionNet(input_channels, sequence_length)\n",
    "\n",
    "# Train 1D CNN\n",
    "# model = EcogToMotionNet()\n",
    "\n",
    "# Train LSTM\n",
    "# model = EcogLSTM(input_size=64, hidden_size=128, num_layers=1, output_size=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6a2ff",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model \n",
    "\n",
    "# Train Linear Model\n",
    "input_channels = X.shape[2]\n",
    "sequence_length = X.shape[1]\n",
    "linear_model = LinearEcogToMotionNet(input_channels, sequence_length)\n",
    "\n",
    "linear_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    linear_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = linear_model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    linear_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            preds = linear_model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val.Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7440c29",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c143e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 1D CNN\n",
    "cnn_model = EcogToMotionNet()\n",
    "\n",
    "cnn_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    cnn_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = cnn_model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    cnn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            preds = cnn_model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val.Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fc935",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488148af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = EcogLSTM(input_size=64, hidden_size=128, num_layers=1, output_size=3)\n",
    "lstm_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    lstm_model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = lstm_model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    lstm_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            preds = lstm_model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val.Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d28eef",
   "metadata": {},
   "source": [
    "# Refined Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Epoch 1/100 | Train Loss: 0.792474 | Val Loss: 0.774172 | R2: 0.253328\n",
      "Model Checkpoint | epoch: 0 | best_val_loss: 0.7741717590975992\n",
      "CNN Epoch 2/100 | Train Loss: 0.726997 | Val Loss: 0.736752 | R2: 0.289478\n",
      "Model Checkpoint | epoch: 1 | best_val_loss: 0.7367517074150091\n",
      "CNN Epoch 3/100 | Train Loss: 0.705741 | Val Loss: 0.796277 | R2: 0.232063\n",
      "CNN Epoch 4/100 | Train Loss: 0.683208 | Val Loss: 0.721690 | R2: 0.304022\n",
      "Model Checkpoint | epoch: 3 | best_val_loss: 0.7216902985475052\n",
      "CNN Epoch 5/100 | Train Loss: 0.675859 | Val Loss: 0.723419 | R2: 0.302353\n",
      "CNN Epoch 6/100 | Train Loss: 0.670785 | Val Loss: 0.673190 | R2: 0.350776\n",
      "Model Checkpoint | epoch: 5 | best_val_loss: 0.6731901810306723\n",
      "CNN Epoch 7/100 | Train Loss: 0.658786 | Val Loss: 0.673207 | R2: 0.350736\n",
      "CNN Epoch 8/100 | Train Loss: 0.651000 | Val Loss: 0.670014 | R2: 0.353841\n",
      "Model Checkpoint | epoch: 7 | best_val_loss: 0.6700141186885853\n",
      "CNN Epoch 9/100 | Train Loss: 0.638856 | Val Loss: 0.650128 | R2: 0.373013\n",
      "Model Checkpoint | epoch: 8 | best_val_loss: 0.6501276521106365\n",
      "CNN Epoch 10/100 | Train Loss: 0.630910 | Val Loss: 0.655743 | R2: 0.367604\n",
      "CNN Epoch 11/100 | Train Loss: 0.635059 | Val Loss: 0.640332 | R2: 0.382488\n",
      "Model Checkpoint | epoch: 10 | best_val_loss: 0.6403317868341961\n",
      "CNN Epoch 12/100 | Train Loss: 0.622113 | Val Loss: 0.667371 | R2: 0.356360\n",
      "CNN Epoch 13/100 | Train Loss: 0.621777 | Val Loss: 0.644787 | R2: 0.378155\n",
      "CNN Epoch 14/100 | Train Loss: 0.621708 | Val Loss: 0.632894 | R2: 0.389629\n",
      "Model Checkpoint | epoch: 13 | best_val_loss: 0.6328941397778736\n",
      "CNN Epoch 15/100 | Train Loss: 0.618706 | Val Loss: 0.653512 | R2: 0.369724\n",
      "CNN Epoch 16/100 | Train Loss: 0.610936 | Val Loss: 0.631397 | R2: 0.391080\n",
      "Model Checkpoint | epoch: 15 | best_val_loss: 0.6313969623990848\n",
      "CNN Epoch 17/100 | Train Loss: 0.607792 | Val Loss: 0.676092 | R2: 0.347927\n",
      "CNN Epoch 18/100 | Train Loss: 0.610026 | Val Loss: 0.634328 | R2: 0.388290\n",
      "CNN Epoch 19/100 | Train Loss: 0.601613 | Val Loss: 0.610371 | R2: 0.411366\n",
      "Model Checkpoint | epoch: 18 | best_val_loss: 0.6103709709817853\n",
      "CNN Epoch 20/100 | Train Loss: 0.600056 | Val Loss: 0.603453 | R2: 0.418032\n",
      "Model Checkpoint | epoch: 19 | best_val_loss: 0.6034528659355483\n",
      "CNN Epoch 21/100 | Train Loss: 0.593911 | Val Loss: 0.632190 | R2: 0.390313\n",
      "CNN Epoch 22/100 | Train Loss: 0.593182 | Val Loss: 0.613832 | R2: 0.407975\n",
      "CNN Epoch 23/100 | Train Loss: 0.586555 | Val Loss: 0.608421 | R2: 0.413224\n",
      "CNN Epoch 24/100 | Train Loss: 0.586402 | Val Loss: 0.630305 | R2: 0.392095\n",
      "CNN Epoch 25/100 | Train Loss: 0.579358 | Val Loss: 0.663737 | R2: 0.359833\n",
      "CNN Epoch 26/100 | Train Loss: 0.572870 | Val Loss: 0.630255 | R2: 0.392127\n",
      "CNN Epoch 27/100 | Train Loss: 0.551247 | Val Loss: 0.561175 | R2: 0.458789\n",
      "Model Checkpoint | epoch: 26 | best_val_loss: 0.5611745412879049\n",
      "CNN Epoch 28/100 | Train Loss: 0.545770 | Val Loss: 0.595237 | R2: 0.425931\n",
      "CNN Epoch 29/100 | Train Loss: 0.545958 | Val Loss: 0.555989 | R2: 0.463774\n",
      "Model Checkpoint | epoch: 28 | best_val_loss: 0.5559890096019223\n",
      "CNN Epoch 30/100 | Train Loss: 0.538954 | Val Loss: 0.564551 | R2: 0.455535\n",
      "CNN Epoch 31/100 | Train Loss: 0.534027 | Val Loss: 0.553133 | R2: 0.466524\n",
      "Model Checkpoint | epoch: 30 | best_val_loss: 0.5531332922012941\n",
      "CNN Epoch 32/100 | Train Loss: 0.534365 | Val Loss: 0.553736 | R2: 0.465964\n",
      "CNN Epoch 33/100 | Train Loss: 0.529455 | Val Loss: 0.550669 | R2: 0.468915\n",
      "Model Checkpoint | epoch: 32 | best_val_loss: 0.5506694291015906\n",
      "CNN Epoch 34/100 | Train Loss: 0.528557 | Val Loss: 0.539125 | R2: 0.480059\n",
      "Model Checkpoint | epoch: 33 | best_val_loss: 0.5391248816522655\n",
      "CNN Epoch 35/100 | Train Loss: 0.523568 | Val Loss: 0.546782 | R2: 0.472664\n",
      "CNN Epoch 36/100 | Train Loss: 0.524233 | Val Loss: 0.544859 | R2: 0.474502\n",
      "CNN Epoch 37/100 | Train Loss: 0.521354 | Val Loss: 0.574489 | R2: 0.445926\n",
      "CNN Epoch 38/100 | Train Loss: 0.520564 | Val Loss: 0.561286 | R2: 0.458704\n",
      "CNN Epoch 39/100 | Train Loss: 0.519679 | Val Loss: 0.552472 | R2: 0.467176\n",
      "CNN Epoch 40/100 | Train Loss: 0.513474 | Val Loss: 0.602250 | R2: 0.419208\n",
      "CNN Epoch 41/100 | Train Loss: 0.501860 | Val Loss: 0.531973 | R2: 0.486929\n",
      "Model Checkpoint | epoch: 40 | best_val_loss: 0.531972784534509\n",
      "CNN Epoch 42/100 | Train Loss: 0.497122 | Val Loss: 0.521681 | R2: 0.496884\n",
      "Model Checkpoint | epoch: 41 | best_val_loss: 0.5216807841025984\n",
      "CNN Epoch 43/100 | Train Loss: 0.496213 | Val Loss: 0.524923 | R2: 0.493761\n",
      "CNN Epoch 44/100 | Train Loss: 0.487422 | Val Loss: 0.517581 | R2: 0.500830\n",
      "Model Checkpoint | epoch: 43 | best_val_loss: 0.5175806830594415\n",
      "CNN Epoch 45/100 | Train Loss: 0.494349 | Val Loss: 0.516150 | R2: 0.502196\n",
      "Model Checkpoint | epoch: 44 | best_val_loss: 0.5161502734364795\n",
      "CNN Epoch 46/100 | Train Loss: 0.486761 | Val Loss: 0.516221 | R2: 0.502134\n",
      "CNN Epoch 47/100 | Train Loss: 0.481900 | Val Loss: 0.510354 | R2: 0.507803\n",
      "Model Checkpoint | epoch: 46 | best_val_loss: 0.5103544237458292\n",
      "CNN Epoch 48/100 | Train Loss: 0.478451 | Val Loss: 0.523060 | R2: 0.495545\n",
      "CNN Epoch 49/100 | Train Loss: 0.480872 | Val Loss: 0.508458 | R2: 0.509624\n",
      "Model Checkpoint | epoch: 48 | best_val_loss: 0.5084576765142595\n",
      "CNN Epoch 50/100 | Train Loss: 0.483282 | Val Loss: 0.509333 | R2: 0.508769\n",
      "CNN Epoch 51/100 | Train Loss: 0.475840 | Val Loss: 0.529688 | R2: 0.489130\n",
      "CNN Epoch 52/100 | Train Loss: 0.478988 | Val Loss: 0.501205 | R2: 0.516609\n",
      "Model Checkpoint | epoch: 51 | best_val_loss: 0.501205131567204\n",
      "CNN Epoch 53/100 | Train Loss: 0.470850 | Val Loss: 0.525200 | R2: 0.493473\n",
      "CNN Epoch 54/100 | Train Loss: 0.467586 | Val Loss: 0.502185 | R2: 0.515676\n",
      "CNN Epoch 55/100 | Train Loss: 0.470082 | Val Loss: 0.510332 | R2: 0.507802\n",
      "CNN Epoch 56/100 | Train Loss: 0.474312 | Val Loss: 0.524884 | R2: 0.493778\n",
      "CNN Epoch 57/100 | Train Loss: 0.470326 | Val Loss: 0.507453 | R2: 0.510569\n",
      "CNN Epoch 58/100 | Train Loss: 0.464508 | Val Loss: 0.520922 | R2: 0.497594\n",
      "CNN Epoch 59/100 | Train Loss: 0.448627 | Val Loss: 0.490285 | R2: 0.527128\n",
      "Model Checkpoint | epoch: 58 | best_val_loss: 0.49028518755729494\n",
      "CNN Epoch 60/100 | Train Loss: 0.450341 | Val Loss: 0.494178 | R2: 0.523380\n",
      "CNN Epoch 61/100 | Train Loss: 0.448944 | Val Loss: 0.497499 | R2: 0.520175\n",
      "CNN Epoch 62/100 | Train Loss: 0.446126 | Val Loss: 0.490410 | R2: 0.527031\n",
      "CNN Epoch 63/100 | Train Loss: 0.442673 | Val Loss: 0.495288 | R2: 0.522317\n",
      "CNN Epoch 64/100 | Train Loss: 0.444170 | Val Loss: 0.501604 | R2: 0.516211\n",
      "CNN Epoch 65/100 | Train Loss: 0.440399 | Val Loss: 0.494113 | R2: 0.523456\n",
      "CNN Epoch 66/100 | Train Loss: 0.433143 | Val Loss: 0.492402 | R2: 0.525094\n",
      "CNN Epoch 67/100 | Train Loss: 0.440808 | Val Loss: 0.485588 | R2: 0.531674\n",
      "Model Checkpoint | epoch: 66 | best_val_loss: 0.4855882375803189\n",
      "CNN Epoch 68/100 | Train Loss: 0.436777 | Val Loss: 0.481899 | R2: 0.535224\n",
      "Model Checkpoint | epoch: 67 | best_val_loss: 0.4818990365977234\n",
      "CNN Epoch 69/100 | Train Loss: 0.434580 | Val Loss: 0.503727 | R2: 0.514177\n",
      "CNN Epoch 70/100 | Train Loss: 0.429062 | Val Loss: 0.491033 | R2: 0.526418\n",
      "CNN Epoch 71/100 | Train Loss: 0.431052 | Val Loss: 0.484113 | R2: 0.533094\n",
      "CNN Epoch 72/100 | Train Loss: 0.431394 | Val Loss: 0.484491 | R2: 0.532728\n",
      "CNN Epoch 73/100 | Train Loss: 0.431180 | Val Loss: 0.481571 | R2: 0.535547\n",
      "Model Checkpoint | epoch: 72 | best_val_loss: 0.4815712183712257\n",
      "CNN Epoch 74/100 | Train Loss: 0.423066 | Val Loss: 0.494773 | R2: 0.522814\n",
      "CNN Epoch 75/100 | Train Loss: 0.426554 | Val Loss: 0.484617 | R2: 0.532595\n",
      "CNN Epoch 76/100 | Train Loss: 0.429163 | Val Loss: 0.487069 | R2: 0.530245\n",
      "CNN Epoch 77/100 | Train Loss: 0.424666 | Val Loss: 0.481773 | R2: 0.535348\n",
      "CNN Epoch 78/100 | Train Loss: 0.425131 | Val Loss: 0.483247 | R2: 0.533929\n",
      "CNN Epoch 79/100 | Train Loss: 0.422262 | Val Loss: 0.483590 | R2: 0.533597\n",
      "CNN Epoch 80/100 | Train Loss: 0.421137 | Val Loss: 0.484826 | R2: 0.532403\n",
      "CNN Epoch 81/100 | Train Loss: 0.421028 | Val Loss: 0.483826 | R2: 0.533377\n",
      "CNN Epoch 82/100 | Train Loss: 0.417897 | Val Loss: 0.479623 | R2: 0.537421\n",
      "Model Checkpoint | epoch: 81 | best_val_loss: 0.4796227431205236\n",
      "CNN Epoch 83/100 | Train Loss: 0.420694 | Val Loss: 0.483608 | R2: 0.533583\n",
      "CNN Epoch 84/100 | Train Loss: 0.418147 | Val Loss: 0.482235 | R2: 0.534909\n",
      "CNN Epoch 85/100 | Train Loss: 0.418609 | Val Loss: 0.484853 | R2: 0.532387\n",
      "CNN Epoch 86/100 | Train Loss: 0.421095 | Val Loss: 0.480832 | R2: 0.536248\n",
      "CNN Epoch 87/100 | Train Loss: 0.409436 | Val Loss: 0.486664 | R2: 0.530635\n",
      "CNN Epoch 88/100 | Train Loss: 0.412356 | Val Loss: 0.483009 | R2: 0.534166\n",
      "CNN Epoch 89/100 | Train Loss: 0.412256 | Val Loss: 0.482297 | R2: 0.534847\n",
      "CNN Epoch 90/100 | Train Loss: 0.412375 | Val Loss: 0.480936 | R2: 0.536158\n",
      "CNN Epoch 91/100 | Train Loss: 0.415384 | Val Loss: 0.481215 | R2: 0.535886\n",
      "CNN Epoch 92/100 | Train Loss: 0.414708 | Val Loss: 0.481415 | R2: 0.535695\n",
      "Early stopping at epoch 92\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnn_train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 79\u001b[0m\n\u001b[1;32m     66\u001b[0m hybrid_train_losses, hybrid_val_losses, hybrid_r2 \u001b[38;5;241m=\u001b[39m train_model(hybrid_model, train_loader, val_loader,device, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 3. Linear\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# input_channels = X.shape[2]\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# sequence_length = X.shape[1]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Plot all losses together\u001b[39;00m\n\u001b[1;32m     77\u001b[0m plot_losses({\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# \"LSTM\": (lstm_train_losses, lstm_val_losses),\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[43mcnn_train_losses\u001b[49m, cnn_val_losses),\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# \"Linear\": (linear_train_losses, linear_val_losses)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn_train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define Training and Test data\n",
    "# Read in the data\n",
    "processed_data_l_X = glob(os.path.join('/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/', '**', \"**\", \"X.npy\"))\n",
    "processed_data_l_y = glob(os.path.join('/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/', '**', \"**\", \"y.npy\"))\n",
    "# Define K-fold sets\n",
    "test_list_X = []\n",
    "train_list_X = []\n",
    "test_list_y = []\n",
    "train_list_y = []\n",
    "\n",
    "for i in range(len(processed_data_l_X)):\n",
    "    test_list_X.append(processed_data_l_X[i])\n",
    "    test_list_y.append(processed_data_l_y[i])\n",
    "    train_X = [x for idx, x in enumerate(processed_data_l_X) if idx != i]\n",
    "    train_y = [y for idx, y in enumerate(processed_data_l_y) if idx != i]\n",
    "    train_list_X.append(train_X)\n",
    "    train_list_y.append(train_y)\n",
    "\n",
    "# Load a single specific dataset\n",
    "# K-Fold 0 uses session 7 as the test set:\n",
    "KFOLD = 0\n",
    "SESSION_SET = 6\n",
    "\n",
    "\"\"\"\n",
    "['/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-24_(S10)/X.npy', 0\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-04-29_(S1)/X.npy', 1\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-06_(S6)/X.npy', 2\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-03_(S5)/X.npy', 3\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-03_(S3)/X.npy', 4\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-03_(S4)/X.npy', 5\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-10_(S8)/X.npy', 6 \n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-05-17_(S9)/X.npy', 7\n",
    " '/home/linux-pc/gh/CRCNS/src/motor_cortex/data/data/Ipsilateral/2018-04-29_(S2)/X.npy'] 8\n",
    "\"\"\"\n",
    "\n",
    "X = np.load(train_list_X[KFOLD][SESSION_SET])\n",
    "y = np.load(train_list_y[KFOLD][SESSION_SET])\n",
    "\n",
    "# X = np.load(test_list_X[0]) # Identify the test set\n",
    "# y = np.load(test_list_y[0]) # Identify the test set\n",
    "\n",
    "# Creating Train and Validation Sets\n",
    "dataset = EcogMotionDataset(X, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "\n",
    "# Assuming train_loader, val_loader, criterion are defined\n",
    "\n",
    "# 2. CNN_LSTM Hybrid Model\n",
    "hybrid_model = EcogToMotionNet()\n",
    "criterion = nn.MSELoss()\n",
    "hybrid_train_losses, hybrid_val_losses, hybrid_r2 = train_model(hybrid_model, train_loader, val_loader,device, epochs=100, model_name=\"Hybrid_CNN_LSTM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LSTM\n",
    "# lstm_model = EcogLSTM(input_size=64, hidden_size=128, num_layers=1, output_size=3)\n",
    "# lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
    "# lstm_train_losses, lstm_val_losses = train_model(lstm_model, train_loader, val_loader, criterion, lstm_optimizer, device, epochs=20, model_name=\"LSTM\")\n",
    "\n",
    "# 3. Linear\n",
    "# input_channels = X.shape[2]\n",
    "# sequence_length = X.shape[1]\n",
    "# linear_model = LinearEcogToMotionNet(input_channels, sequence_length)\n",
    "# linear_optimizer = torch.optim.Adam(linear_model.parameters(), lr=1e-3)\n",
    "# linear_train_losses, linear_val_losses = train_model(linear_model, train_loader, val_loader, criterion, linear_optimizer, device, epochs=20, model_name=\"Linear\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Plot all losses together\n",
    "# plot_losses({\n",
    "#     # \"LSTM\": (lstm_train_losses, lstm_val_losses),\n",
    "#     \"CNN\": (cnn_train_losses, cnn_val_losses),\n",
    "#     # \"Linear\": (linear_train_losses, linear_val_losses)\n",
    "# })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892acd38",
   "metadata": {},
   "source": [
    "## Loading the model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model structure\n",
    "cnn_model = EcogToMotionNet()\n",
    "cnn_model.load_state_dict(torch.load(\"models/Hybrid_best_model_session_8_ipsilateral_2018_05_10.pth\"))\n",
    "cnn_model.to(device)\n",
    "cnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-fold sets\n",
    "test_list_X = []\n",
    "train_list_X = []\n",
    "test_list_y = []\n",
    "train_list_y = []\n",
    "\n",
    "for i in range(len(processed_data_l_X)):\n",
    "    test_list_X.append(processed_data_l_X[i])\n",
    "    test_list_y.append(processed_data_l_y[i])\n",
    "    train_X = [x for idx, x in enumerate(processed_data_l_X) if idx != i]\n",
    "    train_y = [y for idx, y in enumerate(processed_data_l_y) if idx != i]\n",
    "    train_list_X.append(train_X)\n",
    "    train_list_y.append(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0851377",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58814ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_X[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a383535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained on the 8th session and predicting on the first session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ecog_data_file = ecog_data_file_l[8]\n",
    "current_motion_data_file = motion_data_file_l[8]\n",
    "preprocessor = PreprocessData(current_ecog_data_file, current_motion_data_file)\n",
    "X, y = preprocessor.process()\n",
    "preprocessor.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0098217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained using data from session 8; Testing using data from session 1\n",
    "X = np.load(train_list_X[0][1])\n",
    "y = np.load(train_list_y[0][1])\n",
    "scaler = joblib.load(train_list_X[0][1].strip(\"X.npy\") + \"scaler_ecog.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and Validation Sets\n",
    "dataset = EcogMotionDataset(X, y)\n",
    "test_loader = DataLoader(dataset, batch_size=64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0418427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Call\n",
    "cnn_model.to(device)\n",
    "output_file_path = train_list_X[0][1].strip(\"X.npy\") + \"ecog_predictions.mat\"\n",
    "predictions, targets = predict_and_export(cnn_model, test_loader, device, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
