{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e5d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "643660ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ECOG_SAMPLES = 1024398\n",
    "MOTION_SAMPLES = 51293\n",
    "ECOG_CHANNELS = 64\n",
    "WINDOW_SIZE = 20 # 1000 Hz / 50 Hz\n",
    "MOTION_DIMS = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c0dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_path = \"./src/motor_cortex/data/data/Bilateral/2018-07-12_(S1)/motion_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c119ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecog_data_path = \"./src/motor_cortex/data/data/Bilateral/2018-07-12_(S1)/ecog_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5612b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECoG_data = pd.read_csv(ecog_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c94d50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data = pd.read_csv(motion_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7592407",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_columns = motion_data.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c1a7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_data_values = motion_data[motion_data_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf17bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51293, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_data_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb823405",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECoG_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27057ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECoG_data_channels = ECoG_data.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d851d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECoG_data_channel_only = ECoG_data[ECoG_data_channels]\n",
    "ECoG_data_channel_only_values = ECoG_data_channel_only.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a13e0b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51293, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_data_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07d31a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024398, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECoG_data_channel_only_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "129be8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51293"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOTION_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27670100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024398, 64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECoG_data_channel_only_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e2e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51293"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOTION_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2097db42",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mECoG_data_channel_only_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMOTION_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/_core/shape_base.py:460\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    458\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    462\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    463\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "np.stack([ECoG_data_channel_only_values.shape[i*WINDOW_SIZE:(i+1)*WINDOW_SIZE] for i in range(MOTION_SAMPLES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0db31a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create 20 sample windows of ECOG data for each sample of motion\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mECoG_data_channel_only_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMOTION_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/numpy/_core/shape_base.py:460\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    458\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    462\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    463\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# Create 20 sample windows of ECOG data for each sample of motion\n",
    "X = np.stack([ECoG_data_channel_only_values[i*WINDOW_SIZE:(i+1)*WINDOW_SIZE] for i in range(MOTION_SAMPLES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6700e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example arrays \n",
    "\n",
    "ecog = ECoG_data_channel_only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
